name: Test Automation DocGen

on:
    workflow_call:
        inputs:
          DOCGEN_URL:
            required: true
            type: string
            description: "Web URL for DocGen"
        secrets:
          EMAILNOTIFICATION_LOGICAPP_URL_TA:
            required: false
            description: "Logic App URL for email notifications"
        outputs:
          TEST_SUCCESS:
            description: "Whether tests passed"
            value: ${{ jobs.test.outputs.TEST_SUCCESS }}
          TEST_REPORT_URL:
            description: "URL to test report artifact"
            value: ${{ jobs.test.outputs.TEST_REPORT_URL }}

env:
    url: ${{ inputs.DOCGEN_URL }}
    accelerator_name: "DocGen"
permissions:
  contents: read
  actions: read
  
jobs:
  test:
    runs-on: ubuntu-latest
    outputs:
      TEST_SUCCESS: ${{ steps.test1.outcome == 'success' || steps.test2.outcome == 'success' || steps.test3.outcome == 'success' }}
      TEST_REPORT_URL: ${{ steps.upload_report.outputs.artifact-url }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/e2e-test/requirements.txt

      - name: Ensure browsers are installed
        run: python -m playwright install --with-deps chromium

      - name: Open URL
        run: |
          echo "Opening URL: ${{ env.url }}"
          python -m webbrowser "${{ env.url }}"

      - name: Sleep for 30 seconds
        run: sleep 30s
        shell: bash

      - name: Run tests(1)
        id: test1
        run: |
          xvfb-run pytest --headed --html=report/report.html --self-contained-html
        working-directory: tests/e2e-test
        continue-on-error: true

      - name: Sleep for 30 seconds
        if: ${{ steps.test1.outcome == 'failure' }}
        run: sleep 30s
        shell: bash

      - name: Run tests(2)
        if: ${{ steps.test1.outcome == 'failure' }}
        id: test2
        run: |
          xvfb-run pytest --headed --html=report/report.html --self-contained-html
        working-directory: tests/e2e-test
        continue-on-error: true

      - name: Sleep for 60 seconds
        if: ${{ steps.test2.outcome == 'failure' }}
        run: sleep 60s
        shell: bash

      - name: Run tests(3)
        if: ${{ steps.test2.outcome == 'failure' }}
        id: test3
        run: |
          xvfb-run pytest --headed --html=report/report.html --self-contained-html
        working-directory: tests/e2e-test

      - name: Upload test report
        id: upload_report
        uses: actions/upload-artifact@v6
        if: ${{ !cancelled() }}
        with:
          name: test-report
          path: tests/e2e-test/report/*


            
      - name: Generate E2E Test Summary
        if: always()
        run: |
          echo "## ðŸ§ª E2E Test Job Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Field | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          
          # Determine overall test result
          OVERALL_SUCCESS="${{ steps.test1.outcome == 'success' || steps.test2.outcome == 'success' || steps.test3.outcome == 'success' }}"
          if [[ "$OVERALL_SUCCESS" == "true" ]]; then
            echo "| **Job Status** | âœ… Success |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| **Job Status** | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "| **Target URL** | [${{ env.url }}](${{ env.url }}) |" >> $GITHUB_STEP_SUMMARY
          echo "| **Test Report** | [Download Artifact](${{ steps.upload_report.outputs.artifact-url }}) |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### ðŸ“‹ Test Execution Details" >> $GITHUB_STEP_SUMMARY
          echo "| Attempt | Status | Notes |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Test Run 1** | ${{ steps.test1.outcome == 'success' && 'âœ… Passed' || 'âŒ Failed' }} | Initial test execution |" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ steps.test1.outcome }}" == "failure" ]]; then
            echo "| **Test Run 2** | ${{ steps.test2.outcome == 'success' && 'âœ… Passed' || steps.test2.outcome == 'failure' && 'âŒ Failed' || 'â¸ï¸ Skipped' }} | Retry after 30s delay |" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ steps.test2.outcome }}" == "failure" ]]; then
            echo "| **Test Run 3** | ${{ steps.test3.outcome == 'success' && 'âœ… Passed' || steps.test3.outcome == 'failure' && 'âŒ Failed' || 'â¸ï¸ Skipped' }} | Final retry after 60s delay |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "$OVERALL_SUCCESS" == "true" ]]; then
            echo "### âœ… Test Results" >> $GITHUB_STEP_SUMMARY
            echo "- End-to-end tests completed successfully" >> $GITHUB_STEP_SUMMARY
            echo "- Application is functioning as expected" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Test Results" >> $GITHUB_STEP_SUMMARY
            echo "- All test attempts failed" >> $GITHUB_STEP_SUMMARY
            echo "- Check the e2e-test/test job for detailed error information" >> $GITHUB_STEP_SUMMARY
          fi